In our previous video, we discussed the cost function and how we can find different cost values by changing the slope (theta1) of the line. We also saw how the gradient descent curve helps us get closer to the global minimum, which represents the best-fit line with the least cost. However, changing the value of theta1 randomly (like starting with 1, then 0.5, then 0) is not an efficient way to find the best value. To optimize this process, we need to use a convergence algorithm.

The convergence algorithm aims to adjust the slope (theta1) more efficiently until we reach the global minimum. The algorithm works as follows:

1. **Repeat until convergence**: This means we continue adjusting the slope (theta1) until we get to the point where the cost function is minimized, which is the global minimum.

2. **Update theta**: The algorithm uses this equation to update the value of theta:

   $\theta_j = \theta_j - \alpha \cdot \frac{\partial J(\theta)}{\partial \theta_j}$

   - **$\theta_j$**: This is the current value of the slope (theta).
   - **$\alpha$**: This is the learning rate, a small value that controls how quickly we update theta. It helps determine the speed of convergence.
   - **$\frac{\partial J(\theta)}{\partial \theta_j}$**: This is the slope of the cost function at the current point. It tells us if we need to increase or decrease theta to minimize the cost.

3. **Calculating the slope (derivative)**: To adjust the value of theta, we need to know whether the slope is positive or negative. If the slope is negative, we increase theta (because we are moving toward the minimum). If the slope is positive, we decrease theta.

   - If the slope is negative (pointing downwards), we add a positive value to theta.
   - If the slope is positive (pointing upwards), we subtract a positive value from theta.

4. **Convergence**: By repeating this process, we gradually move closer to the global minimum, and the cost function value gets smaller. Once we reach the global minimum, we get the best-fit line.

5. **Learning rate (alpha)**: The learning rate controls how fast or slow the convergence happens. A small learning rate means slower convergence, but too large a value can cause the algorithm to overshoot and not converge. A good practice is to set alpha to values like 0.001.

In simple linear regression, the convergence algorithm helps us adjust the slope efficiently, and it’s widely used in machine learning algorithms to find the best-fit line for any given dataset.

In the next video, we will discuss performance metrics, which are essential to evaluate the model’s accuracy.

Alright! Let's break down what we've covered so far in the context of gradient descent and finding the optimal parameters (theta values) for our linear regression model. We've gone through a detailed explanation of how gradient descent helps in minimizing the cost function and how we update the coefficients iteratively.

### Summary of Key Concepts

1. **Gradient Descent Recap**:
   - Gradient descent is an optimization algorithm used to minimize the cost function $J(\theta)$.
   - The goal is to adjust the coefficients (theta values) in such a way that the cost function is minimized, ideally reaching the global minima.
   - We update the parameters iteratively using the formula:

     $\theta_j := \theta_j - \alpha \frac{\partial J(\theta)}{\partial \theta_j}$

     where:
     - $\theta_j$ is the parameter being updated.
     - $\alpha$ is the learning rate, which controls the step size.
     - $\frac{\partial J(\theta)}{\partial \theta_j}$ is the partial derivative of the cost function with respect to $\theta_j$.

2. **2D Gradient Descent**:
   - Initially, we considered only one parameter $\theta_1$ (assuming $\theta_0 = 0$), which allowed us to visualize the cost function as a 2D curve.
   - The curve represents the cost $J(\theta)$ plotted against $\theta_1$.
   - Our aim was to reach the lowest point on this curve, known as the global minimum, by adjusting $\theta_1$.

3. **Extending to 3D (Two Parameters: $\theta_0$ and $\theta_1$)**:
   - Now, let's consider a more realistic scenario where both $\theta_0$ (intercept) and $\theta_1$ (slope) are present.
   - The cost function now becomes a surface in 3D space, where the axes represent $\theta_0$, $\theta_1$, and $J(\theta)$.
   - The optimization process involves finding the lowest point on this 3D surface, which corresponds to the global minimum.

### Updating Parameters for Multiple Coefficients

In a 3D scenario, we update both $\theta_0$ and $\theta_1$ using gradient descent. Here's the generalized convergence algorithm:

#### Convergence Algorithm

- Repeat until convergence:
  
  $\theta_j := \theta_j - \alpha \frac{\partial J(\theta_0, \theta_1)}{\partial \theta_j}$
  
  - Here, $j$ can be either 0 or 1, meaning we'll have two separate equations for updating $\theta_0$ and $\theta_1$.

#### Cost Function

- The cost function $J(\theta_0, \theta_1)$ for linear regression is defined as:
  
  $J(\theta_0, \theta_1) = \frac{1}{2m} \sum_{i=1}^{m} \left( h_\theta(x_i) - y_i \right)^2$
  
  where:
  - $m$ is the number of training examples.
  - $h_\theta(x_i) = \theta_0 + \theta_1 x_i$ is the hypothesis (prediction).
  - $y_i$ is the actual output for the $i^{th}$ training example.

### Derivatives for Parameter Updates

Let's derive the partial derivatives for both $\theta_0$ and $\theta_1$:

1. **Partial Derivative with Respect to $\theta_0$**:

   $\frac{\partial J(\theta_0, \theta_1)}{\partial \theta_0} = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x_i) - y_i \right)$

2. **Partial Derivative with Respect to $\theta_1$**:

   $\frac{\partial J(\theta_0, \theta_1)}{\partial \theta_1} = \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x_i) - y_i \right) x_i$

### Gradient Descent Update Rules

- Using the derivatives above, the update rules for $\theta_0$ and $\theta_1$ become:

  $\theta_0 := \theta_0 - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x_i) - y_i \right)$
  
  $\theta_1 := \theta_1 - \alpha \cdot \frac{1}{m} \sum_{i=1}^{m} \left( h_\theta(x_i) - y_i \right) x_i$
  
### Explanation of the Algorithm

- At each iteration:
  1. Compute the predicted values $h_\theta(x_i)$.
  2. Calculate the difference between the predicted values and the actual values $(h_\theta(x_i) - y_i)$.
  3. Adjust $\theta_0$ and $\theta_1$ using the update rules to minimize the cost function.
- The process repeats until convergence, meaning the changes in $\theta_0$ and $\theta_1$ become very small.

### Visualizing the Gradient Descent Path

- Imagine the cost function surface as an inverted bowl (convex shape).
- Gradient descent is like a ball rolling down this surface, seeking the lowest point.
- The updates to $\theta_0$ and $\theta_1$ correspond to moving the ball step-by-step towards the bottom (global minimum).

In this video, we're going to discuss three important regression evaluation metrics: **Mean Squared Error (MSE)**, **Mean Absolute Error (MAE)**, and **Root Mean Squared Error (RMSE)**. These metrics help us measure how well our model is performing by focusing on the errors for each data point, unlike **R²** and **Adjusted R²**, which we've already covered in our previous video for assessing the overall fit of the model.

### Introduction to Error Metrics

Let's consider a regression problem where we have a dataset with **years of experience** on the x-axis and **salary** on the y-axis. After training a linear regression model, we get a **best fit line**. This line helps us predict the **salary** based on a given number of years of experience.

For each data point:

- The **actual value** (denoted as $y$) is the true salary.
- The **predicted value** (denoted as $\hat{y}$) is the salary predicted by our model.

The difference between these actual and predicted values is known as the **error**. Our goal is to minimize this error to improve our model's performance. This is where MSE, MAE, and RMSE come into play.

### Mean Squared Error (MSE)

The **Mean Squared Error** is one of the most commonly used metrics to measure the performance of a regression model. Its formula is:

$\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2$

- $y_i$ is the actual value.
- $\hat{y}_i$ is the predicted value.
- $n$ is the number of data points.

**Key Points:**

- MSE calculates the average squared difference between actual and predicted values.
- The squaring of errors means that larger errors have a disproportionately higher impact, making MSE sensitive to outliers.
- It provides a **quadratic** cost function, which is useful for optimization techniques like **gradient descent**.

#### Advantages of MSE

1. **Differentiable**: The squared error function is differentiable, which means we can use techniques like gradient descent to minimize the error effectively.
2. **Single Global Minima**: Because the MSE is a quadratic function, it forms a **convex curve**, meaning there’s only one global minimum. This prevents the model from getting stuck in local minima during optimization.
3. **Convergence**: Due to its convex nature, models trained using MSE typically converge faster.

#### Disadvantages of MSE

1. **Not Robust to Outliers**: Because errors are squared, larger errors are heavily penalized, making MSE sensitive to outliers. If there’s a data point that’s far away from the others, it will disproportionately affect the MSE, causing the model to shift the best fit line to accommodate this outlier.
2. **Units Issue**: The error value produced by MSE is in the squared units of the output variable. For example, if the target variable (like salary) is in lakhs, the MSE would be in lakhs², which can be harder to interpret directly.

### Mean Absolute Error (MAE)

The **Mean Absolute Error** is another metric for evaluating regression models. Its formula is:

$\text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|$

**Key Points:**

- MAE calculates the average of the absolute differences between actual and predicted values.
- Unlike MSE, MAE doesn’t square the errors, so it’s less sensitive to outliers.
- The error value is in the same unit as the target variable, making it easier to interpret.

#### Advantages of MAE

1. **Robust to Outliers**: MAE treats all errors equally and doesn’t disproportionately penalize larger errors, making it more robust to outliers.
2. **Interpretable Units**: The error is measured in the same units as the original data, making it easier to understand.

#### Disadvantages of MAE

1. **Non-Differentiable at Zero**: The absolute value function is not differentiable at zero, which can complicate the optimization process.
2. **No Convexity Guarantee**: The loss surface of MAE isn’t convex like MSE, which may result in multiple local minima, making optimization harder.

### Root Mean Squared Error (RMSE)

The **Root Mean Squared Error** is essentially the square root of MSE:

$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2}$

**Key Points:**

- RMSE gives an error value in the same units as the target variable, like MAE.
- It balances between penalizing large errors (like MSE) and providing interpretable results (like MAE).

#### Advantages of RMSE

1. **Penalizes Large Errors**: Like MSE, RMSE penalizes larger errors more significantly, which can be useful if we want to focus on minimizing large deviations.
2. **Interpretable Units**: RMSE is in the same unit as the target variable, making it more interpretable than MSE.

#### Disadvantages of RMSE

1. **Still Sensitive to Outliers**: Although not as sensitive as MSE, RMSE can still be affected by outliers due to the squaring of errors before taking the square root.
2. **Higher Computational Cost**: Calculating the square root can add computational overhead, especially with large datasets.

### Summary of Metrics

| Metric | Formula | Robust to Outliers? | Units | Differentiable? |
|--------|---------|---------------------|-------|-----------------|
| MSE    | $\frac{1}{n} \sum (y_i - \hat{y}_i)^2$ | No  | Squared Units | Yes |
| MAE    | $\frac{1}{n} \sum |y_i - \hat{y}_i|$ | Yes | Same as target | No at zero |
| RMSE   | $\sqrt{\frac{1}{n} \sum (y_i - \hat{y}_i)^2}$ | No (less than MSE) | Same as target | Yes |

### Conclusion

- Use **MSE** if you want a differentiable loss function and can tolerate sensitivity to outliers.
- Use **MAE** if you need robustness to outliers and interpretability in the same units.
- Use **RMSE** as a balanced approach between MSE and MAE, especially if you want interpretable error values but can tolerate some sensitivity to outliers.

By understanding the strengths and weaknesses of each metric, you can choose the most appropriate one based on your specific regression problem and dataset characteristics.
