{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1107dfe7-bc7c-4be0-a366-c241fb9f0a96",
   "metadata": {},
   "source": [
    "It seems like you're explaining the concept of data encoding in machine learning, specifically focusing on one-hot encoding (also known as nominal encoding). Here's a breakdown of the key points from your video script:\n",
    "\n",
    "### What is Data Encoding?\n",
    "- **Purpose of Data Encoding**: Data encoding is necessary to convert categorical variables (like degrees or colors) into numerical values because machine learning algorithms can only interpret numerical data.\n",
    "- **Problem with Categorical Data**: While humans can understand categorical variables (e.g., degrees like PhD, Masters, Bachelors), models don't understand these terms directly. Therefore, encoding is required to convert them into a numerical format that a model can process.\n",
    "\n",
    "### Types of Data Encoding:\n",
    "1. **Nominal (One-Hot) Encoding**:\n",
    "   - This technique creates binary columns for each category in the feature.\n",
    "   - For example, if the categorical variable is \"color\" with values red, green, and blue, one-hot encoding will create three new columns: one for each color. If the data point is red, it gets represented as [1, 0, 0], for green as [0, 1, 0], and for blue as [0, 0, 1].\n",
    "   - **Advantage**: Ensures that no order is implied in the categories.\n",
    "   - **Disadvantage**: If there are many categories, it can create a large number of features, leading to high memory usage and possibly sparse matrices that may cause overfitting.\n",
    "\n",
    "2. **Label (Ordinal) Encoding**:\n",
    "   - This method assigns a unique integer to each category. For example, the values \"Bachelors\", \"Masters\", and \"PhD\" could be encoded as 1, 2, and 3, respectively.\n",
    "   - **Advantage**: Works well when there is an inherent order in the categories (like education levels).\n",
    "   - **Disadvantage**: Imposes a numeric order, which may not always be appropriate for nominal categories (i.e., categories without inherent order).\n",
    "\n",
    "3. **Target Guided Ordinal Encoding**:\n",
    "   - This approach assigns numerical values based on the target variable (the outcome you want to predict). For example, you could encode categories based on the mean of the target variable for each category.\n",
    "   - **Advantage**: Can be more effective when there is a relationship between the categorical variable and the target.\n",
    "   - **Disadvantage**: This approach can lead to overfitting if the model is trained on small or noisy data.\n",
    "\n",
    "### Implementing One-Hot Encoding in Python:\n",
    "- **Pandas and Sklearn**: You demonstrated how to use the `OneHotEncoder` class from `sklearn.preprocessing` to convert a categorical feature into multiple binary features.\n",
    "- You first created a DataFrame with a \"color\" feature containing categories like red, blue, and green.\n",
    "- Then you used `fit_transform` to apply one-hot encoding, creating a sparse matrix that was later converted into a regular array.\n",
    "- Finally, you showed how to concatenate the encoded features back into the original DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5b49a4f9-171e-46e2-bbe3-6a413a990d16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   color  color_blue  color_green  color_red\n",
      "0    red         0.0          0.0        1.0\n",
      "1   blue         1.0          0.0        0.0\n",
      "2  green         0.0          1.0        0.0\n",
      "3  green         0.0          1.0        0.0\n",
      "4    red         0.0          0.0        1.0\n",
      "5   blue         1.0          0.0        0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Creating a sample DataFrame\n",
    "df = pd.DataFrame({'color': ['red', 'blue', 'green', 'green', 'red', 'blue']})\n",
    "\n",
    "# Creating an instance of OneHotEncoder\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Applying one-hot encoding\n",
    "encoded_data = encoder.fit_transform(df[['color']])\n",
    "\n",
    "# Converting the encoded data into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_data, columns=encoder.get_feature_names_out())\n",
    "\n",
    "# Concatenating original and encoded features\n",
    "final_df = pd.concat([df, encoded_df], axis=1)\n",
    "print(final_df)\n",
    "\n",
    "v = \"\"\"\n",
    "### Output:\n",
    "   color  color_blue  color_green  color_red\n",
    "0    red         0.0          0.0        1.0\n",
    "1   blue         1.0          0.0        0.0\n",
    "2  green         0.0          1.0        0.0\n",
    "3  green         0.0          1.0        0.0\n",
    "4    red         0.0          0.0        1.0\n",
    "5   blue         1.0          0.0        0.0\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3ef05c-b8b6-4b5c-b6f8-dedaf55bb4f0",
   "metadata": {},
   "source": [
    "### Key Takeaways:\n",
    "- **One-Hot Encoding**: Converts categorical data into multiple binary columns.\n",
    "- **Sparse Matrix**: One-hot encoding can lead to a sparse matrix with lots of zeroes, especially with many categories.\n",
    "- **Usage**: It’s useful when categories do not have an inherent order (e.g., colors, types of fruits).\n",
    "- **Overfitting Risk**: Using one-hot encoding with a very high number of categories can lead to overfitting and increased model complexity.\n",
    "\n",
    "This is a great way to introduce the concept of data encoding and walk through the Python implementation with practical examples!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "866dad7c-4b55-4984-8a55-be0a4660cda6",
   "metadata": {},
   "source": [
    "It looks like you're explaining **Label Encoding** and **Ordinal Encoding** techniques in Python, specifically using `sklearn`. Let me break down what you've covered:\n",
    "\n",
    "### 1. **Label Encoding**\n",
    "- **What is it?** Label Encoding is a technique used to convert categorical values into numerical values. Each category gets a unique integer label.\n",
    "  \n",
    "- **Example:**\n",
    "  If you have categories like `Red`, `Green`, `Blue`, label encoding might assign:\n",
    "  - `Red` → `2`\n",
    "  - `Green` → `1`\n",
    "  - `Blue` → `0`\n",
    "  \n",
    "  This encoding is applied in a sorted order of the categorical values.\n",
    "\n",
    "- **Potential Issue:** While it works well for machine learning models, it can create an unintended ordinal relationship (i.e., `Green` > `Blue` because `1` > `0`), which doesn't make sense for nominal (unordered) categories like color.\n",
    "\n",
    "### 2. **Ordinal Encoding**\n",
    "- **What is it?** Ordinal Encoding is used when categorical variables have an inherent order (ranking). Here, each category gets assigned a rank or value that reflects its order.\n",
    "  \n",
    "- **Example:**\n",
    "  For a variable like `Education Level`, with categories like `High School`, `College`, `Graduate`, `Post Graduate`, you can assign ranks based on their levels:\n",
    "  - `High School` → `0`\n",
    "  - `College` → `1`\n",
    "  - `Graduate` → `2`\n",
    "  - `Post Graduate` → `3`\n",
    "  \n",
    "  This technique is used when the categorical variables carry meaning in terms of their order.\n",
    "\n",
    "- **Code Implementation:**\n",
    "  - You used the `OrdinalEncoder` from `sklearn.preprocessing` to assign ordinal values to a categorical feature like `Size` (with values `Small`, `Medium`, `Large`). \n",
    "  - The categories are assigned ranks where `Small` gets rank `0`, `Medium` gets `1`, and `Large` gets `2`.\n",
    "\n",
    "  ```python\n",
    "  from sklearn.preprocessing import OrdinalEncoder\n",
    "  \n",
    "  encoder = OrdinalEncoder(categories=[['Small', 'Medium', 'Large']])\n",
    "  df['Size_encoded'] = encoder.fit_transform(df[['Size']])\n",
    "  ```\n",
    "\n",
    "### 3. **Limitations of Label Encoding**\n",
    "- One issue with Label Encoding, as you've mentioned, is that machine learning models might interpret the numerical labels as having a natural order (such as `1` being \"greater\" than `0`), which can mislead the model when working with nominal data.\n",
    "- **Solution:** Use **Ordinal Encoding** when the categories have a natural order (like `Education Level` or `Ranking`).\n",
    "\n",
    "### 4. **Target Guided Ordinal Encoding (coming up)**\n",
    "- This technique assigns ranks based on the target variable's relationship with the categories, rather than just the category values themselves. It's useful when you want to create a more meaningful encoding based on how categories influence the target.\n",
    "\n",
    "This is a solid overview of **Label Encoding** and **Ordinal Encoding**. If you're moving on to **Target Guided Ordinal Encoding**, that will be a great next step, especially for cases where categorical variables interact with the target variable to create meaningful rank-based encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6eb68b-921a-4ee6-a83d-9459d2959845",
   "metadata": {},
   "source": [
    "### Target Guided Ordinal Encoding Explained with Steps and Example\n",
    "\n",
    "#### What is Target Guided Ordinal Encoding?\n",
    "Target guided ordinal encoding is a **feature engineering technique** where we encode a categorical variable based on its relationship with the target variable. It’s particularly useful when the categorical variable has many unique categories and we want to preserve its relationship with the target variable.\n",
    "\n",
    "The encoding replaces each category with a **numerical value** derived from a statistic (mean or median) of the target variable for that category.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why Use Target Guided Ordinal Encoding?\n",
    "1. **Handles High Cardinality**: Effective for categorical features with many unique categories.\n",
    "2. **Captures Relationships**: Reflects the impact of categories on the target variable in a meaningful way.\n",
    "3. **Model Compatibility**: Converts categorical data into numerical form suitable for machine learning models.\n",
    "\n",
    "---\n",
    "\n",
    "#### Step-by-Step Explanation with Example\n",
    "1. **Dataset Overview**  \n",
    "   Example dataset with two features:\n",
    "   - `City` (categorical variable)\n",
    "   - `Price` (target variable)\n",
    "\n",
    "   | City       | Price  |\n",
    "   |------------|--------|\n",
    "   | New York   | 200    |\n",
    "   | London     | 150    |\n",
    "   | Paris      | 320    |\n",
    "   | Tokyo      | 250    |\n",
    "   | New York   | 180    |\n",
    "   | Paris      | 300    |\n",
    "\n",
    "2. **Compute Mean or Median for Each Category**  \n",
    "   Group the data by `City` and calculate the mean of the `Price` for each category.\n",
    "\n",
    "   ```python\n",
    "   mean_price = df.groupby('City')['Price'].mean().to_dict()\n",
    "   ```\n",
    "\n",
    "   Resulting dictionary:\n",
    "\n",
    "   ```python\n",
    "   mean_price = {\n",
    "       'London': 150,\n",
    "       'New York': 190,  # (200+180)/2\n",
    "       'Paris': 310,     # (320+300)/2\n",
    "       'Tokyo': 250\n",
    "   }\n",
    "   ```\n",
    "\n",
    "3. **Map Categorical Values to Encoded Values**  \n",
    "   Replace the `City` column with its corresponding mean value from `mean_price`.\n",
    "\n",
    "   ```python\n",
    "   df['City_Encoded'] = df['City'].map(mean_price)\n",
    "   ```\n",
    "\n",
    "   Updated dataset:\n",
    "\n",
    "   | City       | Price  | City_Encoded |\n",
    "   |------------|--------|--------------|\n",
    "   | New York   | 200    | 190          |\n",
    "   | London     | 150    | 150          |\n",
    "   | Paris      | 320    | 310          |\n",
    "   | Tokyo      | 250    | 250          |\n",
    "   | New York   | 180    | 190          |\n",
    "   | Paris      | 300    | 310          |\n",
    "\n",
    "4. **Prepare Final Dataset**  \n",
    "   Drop the original `City` column and use `City_Encoded` along with the `Price` for model training.\n",
    "\n",
    "   ```python\n",
    "   df = df[['City_Encoded', 'Price']]\n",
    "   ```\n",
    "\n",
    "   Final dataset:\n",
    "\n",
    "   | City_Encoded | Price  |\n",
    "   |--------------|--------|\n",
    "   | 190          | 200    |\n",
    "   | 150          | 150    |\n",
    "   | 310          | 320    |\n",
    "   | 250          | 250    |\n",
    "   | 190          | 180    |\n",
    "   | 310          | 300    |\n",
    "\n",
    "---\n",
    "\n",
    "#### Practical Application Exercise\n",
    "**Task**: Use the `tips` dataset from Seaborn and apply target guided ordinal encoding.  \n",
    "- Target: `total_bill`\n",
    "- Feature: `time` (categorical)\n",
    "\n",
    "Steps:\n",
    "1. Load the dataset.\n",
    "   ```python\n",
    "   import seaborn as sns\n",
    "   df = sns.load_dataset('tips')\n",
    "   ```\n",
    "\n",
    "2. Apply the encoding technique to `time` based on the mean of `total_bill`.\n",
    "\n",
    "   ```python\n",
    "   mean_total_bill = df.groupby('time')['total_bill'].mean().to_dict()\n",
    "   df['time_encoded'] = df['time'].map(mean_total_bill)\n",
    "   ```\n",
    "\n",
    "3. Validate the transformed dataset and use the new encoded feature for modeling.\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Takeaways\n",
    "- **Efficiency**: Captures the influence of categories on the target.\n",
    "- **Interpretability**: Allows models to assign importance to categories based on target correlation.\n",
    "- **Customizable**: Choose mean or median based on data characteristics.\n",
    "\n",
    "This technique is a powerful tool in preprocessing categorical data for regression or classification tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a865b95e-0477-4d1a-91bc-d975701652ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
